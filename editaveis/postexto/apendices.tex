\begin{apendicesenv}
%
\partapendices
%
\chapter{PRINCÍPIOS SEGUIDOS PELO INTERSCITY}
\label{appendix:principles}

O InterSCity foi desenvolvido utilizando princípios de \textit{design}, e,
assim, busca atender critérios estabelecidos. Os princípios são:

\begin{itemize}
    \item \textbf{Modularidade através de serviços}: O InterSCity se torna mais
modular através da criação de mais microsserviços, que buscam ter
responsabilidades atômicas e bem definidas \cite{delesposte2017}.

    \item \textbf{Modelos e Dados Distribuídos}: O InterSCity melhora sua
escalabilidade através da distribuição dos dados e dos modelos. Com essa
prática, cada microsserviço pode evoluir separadamente, por contar com seu
próprio banco de dados \cite{delesposte2017}. Contudo, esse princípio apresenta
o ponto negativo de aumentar a complexidade.

    \item \textbf{Evolução Descentralizada}: Por conta do não-acoplamento, é
possível que módulos do InterSCity evoluam e sofram manutenção
independentemente, sem afetar outros microsserviços da plataforma
\cite{delesposte2017}.

    \item \textbf{Reuso de Projetos de Código Aberto}: O InterSCity preferencia % uso software livre ou codigo aberto?
projetos robustos já desenvolvidos, ao invés de desenvolver soluções do zero
\cite{delesposte2017}. Contudo, esta escolha é feita com cuidado, e somente
projetos com colaboradores e mantenedores ativos, e com documentação
apropriada, são utilizadas na plataforma \cite{delesposte2017}.

    \item \textbf{Adoção de Padrões Abertos}: O InterSCity adota padrões já
difundidos, para que seja provida maior interoperabilidade entre a plataforma
e outros projetos \cite{delesposte2017}.

    \item \textbf{Assíncrono contra Síncrono}: O InterSCity busca prover
serviços e atividades assíncronas sempre que possível, com a finalidade de
evitar que eventos blocantes ocorram. Isto é atingido principalmente através
do padrão PubSub, e de estratégias baseadas em eventos \cite{delesposte2017}.

    \item \textbf{Serviços sem Estado}: Os microsserviços do InterSCity evitam,
sempre que possível, ter um estado específico \cite{delesposte2017}. Com isso,
os microsserviços podem responder a qualquer requisição a qualquer momento, ao
contrário do que ocorreria caso tivessem estados específicos, pois só
conseguiriam caso certas transições ocorressem.
\end{itemize}

\chapter{PSEUDO-IMPLEMENTAÇÃO - ARQUITETURA LAMBDA}

O Shock só apresenta a implementação da Arquitetura Kappa, e, como forma de
complementação, deixamos disponível uma pseudo-implementação com a utilização
da Arquitetura Lambda.

\label{appendix:impl}

\section{CÓDIGO DA CAMADA BATCH}
\begin{python}
class BatchLayer(threading.Thread):
    daemon = True
    ...
    def run(self):
        heappush(hooks.actions, (10, Handler1.AcquireData))
        heappush(hooks.actions, (12, Handler2.AdjustDataModels))
        heappush(hooks.actions, (20, Handler3.ProcessData))
        heappush(hooks.actions, (21, Handler4.FindAnomalies))
        # extensible, new hooks can be added

        self.batch_view = sc.emptyRDD()

        while (True):
            # continuously processing
            rdd = spark.sql("SELECT * FROM sensor_data").cache()
                for op in hooks.actions:
                rdd = op(rdd).cache()
            self.batch_view = rdd # updates batch view
            rdd.unpersist()
            self.finished_batch = True # notifies speed layer
\end{python}

\section{CÓDIGO DA CAMADA SPEED}
\begin{python}
class SpeedLayer(threading.Thread):
    daemon = True
    ...
    def run(self):
        self.reset_realtime_view = False
        self.new_realtime_view = False

        def reset_realtime_view(stream):
            # checks if the batch layer finished its processing
            if (batch_view.finished_batch):
                batch_view.finished_batch = False
                stream.foreachRDD(lambda rdd: rdd.unpersist())
                self.reset_realtime_views = True
                return stream.filter(lambda a: false)
            else:
                return stream

        def notify_serving(stream):
            self.new_realtime_view = True

        # connects to Kafka
        kvs = KafkaUtils.createDirectStream(ssc, [topic], \\
            {"metadata.broker.list": brokers})

        heappush(hooks.actions, (10, Handler1.AcquireData))
        heappush(hooks.actions, (12, Handler2.AdjustDataModels))
        heappush(hooks.actions, (20, Handler3.ProcessData))
        heappush(hooks.actions, (21, Handler4.FindAnomalies))
        heappush(hooks.actions, (0xfffff, notify_serving))
        heappush(hook.actions, (0xffffff, lambda realtime_view: \
            reset_realtime_view(realtime_view)))

        self.realtime_view = kvs
        for op in hook.actions:
              # register hooks to be executed by the stream
              self.realtime_view = op(self.realtime_view)

        ssc.start() # start the stream
        ssc.awaitTermination()

\end{python}

\section{CÓDIGO DA CAMADA SERVING}
\begin{python}
class ServingLayer:
    ...
    def start(self):
        merged_data = sc.emptyRDD()
        speed_layer = SpeedLayer()
        batch_layer = BatchLayer()
        while (True):
            if (speed_layer.new_realtime_view):
                # updates results with available realtime views
                speed_layer.new_realtime_view = False
                merged_data = merged_data.union(\
                    speed_layer.realtime_view)
            if (speed_layer.reset_realtime_view):
                # reset realtime views when batches finishes
                merged_data = batch_layer.batch_view
                speed_layer.reset_realtime_view = False
            if (query):
                query(merged_data)
\end{python}

\end{apendicesenv}

